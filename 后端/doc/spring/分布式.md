### 微服务的优点

1. 独立开发 
2. 独立部署
3. 故障隔离
4. 混合技术堆栈
5. 粒度缩放

### 微服务的特点

1. 解耦
2. 组件化
3. 业务能力单一
4. 自治
5. 持续交付
6. 责任
7. 分散治理
8. 敏捷



### 微服务架构的优缺点

| 优点                       | 缺点                         |
| -------------------------- | ---------------------------- |
| 自由使用不同技术           | 增加故障排除挑战             |
| 每个微服务都侧重单一功能   | 由于远程呼叫而增加延迟       |
| 支持单个可部署单元         | 增加了配置和其他操作的工作量 |
| 允许经常发布软件           | 难以保持交易安全             |
| 确保每项服务的安全性       | 艰难地跨越各种边界跟踪数据   |
| 多个服务是并行开发和部署的 | 难以在服务之间进行编码       |



### 大型网站架构演化发展历程

1. 初始阶段的网站架构

   大型网站都是从小型网站发展而来，网站架构也是一样，是从小型网站架构逐步演化而来。小型网站最开始没有太多人访问，只需要一台服务器就绰绰有余，这时的网站架应用程序、数据库、文件等所有资源都在一台服务器上

2. 应用服务和数据服务分离

   随着网站业务的发展，一台服务器逐渐不能满足需求：越来越多的用户访问导致性能越来越差，越来越多的数据导致存储空间不足。这时就需要将应用和数据分离。应用和数据分离后整个网站使用3台服务器：应用服务器、文件服务器和数据库服务器。这 3 台服务器对硬件资源的要求各不相同

   - 应用服务器需要处理大量的业务逻辑，因此需要更快更强大的CPU；
   - 数据库服务器需要快速磁盘检索和数据缓存，因此需要更快的磁盘和更大的内存；
   - 文件服务器需要存储大量用户上传的文件，因此需要更大的硬盘

   ![image-20210810201644938](https://gitee.com/Sean0516/image/raw/master/img/image-20210810201644938.png)

   应用和数据分离后，不同特性的服务器承担不同的服务角色，网站的并发处理能力和数据存储空间得到了很大改善，支持网站业务进一步发展。但是随着用户逐渐增多，网站又一次面临挑战：数据库压力太大导致访问延迟，进而影响整个网站的性能，用户体验受到影响。这时需要对网站架构进一步优化

3. 使用缓存改善网站性能

   网站访问的特点和现实世界的财富分配一样遵循二八定律：80% 的业务访问集中在20% 的数据上。既然大部分业务访问集中在一小部分数据上，那么如果把这一小部分数据缓存在内存中，就可以减少数据库的访问压力，提高整个网站的数据访问速度，改善数据库的写入性能了。 网站使用的缓存可以分为两种：缓存在应用服务器上的本地缓存和缓存在专门的分布式缓存服务器上的远程缓存

   - ​	本地缓存的访问速度更快一些，但是受应用服务器内存限制，其缓存数据量有限，而且会出现和应用程序争用内存的情况
   - 远程分布式缓存可以使用集群的方式，部署大内存的服务器作为专门的缓存服务器，可以在理论上做到不受内存容量限制的缓存服务

   ![image-20210810201937777](https://gitee.com/Sean0516/image/raw/master/img/image-20210810201937777.png)

   使用缓存后，数据访问压力得到有效缓解，但是单一应用服务器能够处理的请求连接有限，在网站访问高峰期，应用服务器成为整个网站的瓶颈

4. 使用应用服务器集群改善网站的并发处理能力

   使用集群是网站解决高并发、海量数据问题的常用手段。当一台服务器的处理能力、存储空间不足时，不要企图去更换更强大的服务器，对大型网站而言，不管多么强大的服务器，都满足不了网站持续增长的业务需求。这种情况下，更恰当的做法是增加一台服务器分担原有服务器的访问及存储压力。 对网站架构而言，只要能通过增加一台服务器的方式改善负载压力，就可以以同样的方式持续增加服务器不断改善系统性能，从而实现系统的可伸缩性。应用服务器实现集群是网站可伸缩架构设计中较为简单成熟的一种

   ![image-20210810202159828](https://gitee.com/Sean0516/image/raw/master/img/image-20210810202159828.png)

   通过负载均衡调度服务器，可以将来自用户浏览器的访问请求分发到应用服务器集群中的任何一台服务器上，如果有更多用户，就在集群中加入更多的应用服务器，使应用服务器的压力不再成为整个网站的瓶颈

5. 数据库读写分离

   网站在使用缓存后，使对大部分数据读操作访问都可以不通过数据库就能完成，但是仍有一部分读操作（缓存访问不命中、缓存过期）和全部的写操作都需要访问数据库，在网站的用户达到一定规模后，数据库因为负载压力过高而成为网站的瓶颈。 目前大部分的主流数据库都提供主从热备功能，通过配置两台数据库主从关系，可以将一台数据库服务器的数据更新同步到另一台服务器上。网站利用数据库的这一功能，实现数据库读写分离，从而改善数据库负载压力。如下图所示

   ![image-20210810202247655](https://gitee.com/Sean0516/image/raw/master/img/image-20210810202247655.png)

   应用服务器在写数据的时候，访问主数据库，主数据库通过主从复制机制将数据更新同步到从数据库，这样当应用服务器读数据的时候，就可以通过从数据库获得数据。为了便于应用程序访问读写分离后的数据库，通常在应用服务器端使用专门的数据访问模块，使数据库读写分离对应用透明

6. 使用反向代理和 CDN 加速网站响应

   随着网站业务不断发展，用户规模越来越大，由于中国复杂的网络环境，不同地区的用户访问网站时，速度差别也极大。有研究表明，网站访问延迟和用户流失率正相关，网站访问越慢，用户越容易失去耐心而离开。为了提供更好的用户体验，留住用户，网站需要加速网站访问速度。主要手段有使用 CDN 和方向代理。如下图所示

   ![image-20210810202342984](https://gitee.com/Sean0516/image/raw/master/img/image-20210810202342984.png)

   CDN 和反向代理的基本原理都是缓存

   CDN 部署在网络提供商的机房，使用户在请求网站服务时，可以从距离自己最近的网络提供商机房获取数据
   反向代理则部署在网站的中心机房，当用户请求到达中心机房后，首先访问的服务器是反向代理服务器，如果反向代理服务器中缓存着用户请求的资源，就将其直接返回给用户

   使用 CDN 和反向代理的目的都是尽早返回数据给用户，一方面加快用户访问速度，另一方面也减轻后端服务器的负载压力

7. 使用分布式文件系统和分布式数据库系统

   任何强大的单一服务器都满足不了大型网站持续增长的业务需求。数据库经过读写分离后，从一台服务器拆分成两台服务器，但是随着网站业务的发展依然不能满足需求，这时需要使用分布式数据库。文件系统也一样，需要使用分布式文件系统。如下图所示

   ![image-20210810202435081](https://gitee.com/Sean0516/image/raw/master/img/image-20210810202435081.png)

   分布式数据库是网站数据库拆分的最后手段，只有在单表数据规模非常庞大的时候才使用。不到不得已时，网站更常用的数据库拆分手段是业务分库，将不同业务的数据部署在不同的物理服务器上

8. 使用 NoSQL 和搜索引擎

   随着网站业务越来越复杂，对数据存储和检索的需求也越来越复杂，网站需要采用一些非关系数据库技术如NoSQL 和非数据库查询技术如搜索引擎。如下图所示

   ![image-20210810202510779](https://gitee.com/Sean0516/image/raw/master/img/image-20210810202510779.png)

   NoSQL 和搜索引擎都是源自互联网的技术手段，对可伸缩的分布式特性具有更好的支持。应用服务器则通过一个统一数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦

9. 分布式微服务

   随着业务拆分越来越小，存储系统越来越庞大，应用系统的整体复杂度呈指数级增加，部署维护越来越困难。由于所有应用要和所有数据库系统连接，在数万台服务器规模的网站中，这些连接的数目是服务器规模的平方，导致数据库连接资源不足，拒绝服务

   既然每一个应用系统都需要执行许多相同的业务操作，比如用户管理、商品管理等，那么可以将这些共用的业务提取出来，独立部署。由这些可复用的业务连接数据库，提供共用业务服务，而应用系统只需要管理用户界面，通过分布式服务调用共用业务服务完成具体业务操作。如下图所示

   ![image-20210810202601384](https://gitee.com/Sean0516/image/raw/master/img/image-20210810202601384.png)

## 数据库架构发展历程

#### 单机MySQL的美好年代

在90年代，一个网站的访问量一般都不大，用单个数据库完全可以轻松应付。 在那个时候，更多的都是静态网页，动态交互类型的网站不多

#### Memcached(缓存)+MySQL+垂直拆分

![image-20210810205446182](https://gitee.com/Sean0516/image/raw/master/img/image-20210810205446182.png)

Memcached作为一个独立的分布式的缓存服务器，为多个web服务器提供了一个共享的高性能缓存服务，在Memcached服务器上，又发展了根据hash算法来进行多台Memcached缓存服务的扩展，然后又出现了一致性hash来解决增加或减少缓存服务器导致重新hash带来的大量缓存失效的弊端

#### Mysql主从复制读写分离

由于数据库的写入压力增加，Memcached只能缓解数据库的读取压力。读写集中在一个数据库上让数据库不堪重负，大部分网站开始使用主从复制技术来达到读写分离，以提高读写性能和读库的可扩展性。Mysql的master-slave模式成为这个时候的网站标配了

![image-20210810205528955](https://gitee.com/Sean0516/image/raw/master/img/image-20210810205528955.png)

#### 分表分库+水平拆分+mysql集群

在Memcached的高速缓存，MySQL的主从复制，读写分离的基础之上，这时MySQL主库的写压力开始出现瓶颈，而数据量的持续猛增，由于MyISAM使用表锁，在高并发下会出现严重的锁问题，大量的高并发MySQL应用开始使用InnoDB引擎代替MyISAM

### 数据的水平拆分和垂直拆分

当我们使用读写分离、缓存后，数据库的压力还是很大的时候，这就需要使用到数据库拆分了。
数据库拆分简单来说，就是指通过某种特定的条件，按照某个维度，将我们存放在同一个数据库中的数据分散存放到多个数据库（主机）上面以达到分散单库（主机）负载的效果

#### 垂直拆分

一个数据库由很多表的构成，每个表对应着不同的业务，垂直切分是指按照业务将表进行分类，分布到不同的数据库上面，这样也就将数据或者说压力分担到不同的库上面

![image-20210812113519461](https://gitee.com/Sean0516/image/raw/master/img/image-20210812113519461.png)

###### 优点

1. 拆分后业务清晰，拆分规则明确
2. 系统之间整合或扩展容易
3. 数据维护简单

###### 缺点

1. 部分业务表无法join，只能通过接口方式解决，提高了系统复杂度
2. 受每种业务不同的限制存在单库性能瓶颈，不易数据扩展跟性能提高
3. 事务处理复杂

#### 水平拆分

垂直拆分后遇到单机瓶颈，可以使用水平拆分。相对于垂直拆分的区别是：垂直拆分是把不同的表拆到不同的数据库中，而水平拆分是把同一个表拆到不同的数据库中

相对于垂直拆分，水平拆分不是将表的数据做分类，而是按照某个字段的某种规则来分散到多个库之中，每个表中包含一部分数据。简单来说，我们可以将数据的水平切分理解为是按照数据行的切分，就是将表中 的某些行切分到一个数据库，而另外的某些行又切分到其他的数据库中，主要有分表，分库两种模式

###### 优点

1. 不存在单库大数据，高并发的性能瓶颈
2. 对应用透明，应用端改造较少。
3. 按照合理拆分规则拆分，join操作基本避免跨库
4. 提高了系统的稳定性跟负载能力。

###### 缺点

1. 拆分规则难以抽象
2. 分片事务一致性难以解决
3. 数据多次扩展难度跟维护量极大。
4. 跨库join性能较差

### 拆分的处理难点

1. 引入分布式事务的问题
2. 跨节点Join 的问题
3. 跨节点合并排序分页问题

针对数据源管理，目前主要有两种思路

1. 客户端模式，在每个应用程序模块中配置管理自己需要的一个（或者多个）数据源，直接访问各个 数据库，在模块内完成数据的整合
   - 优点：相对简单，无性能损耗。
   - 缺点：不够通用，数据库连接的处理复杂，对业务不够透明，处理复杂
2. 通过中间代理层来统一管理所有的数据源，后端数据库集群对前端应用程序透明
   - 优点：通用，对应用透明，改造少
   - 缺点：实现难度大，有二次转发性能损失

#### 拆分原则

1. 尽量不拆分，架构是进化而来，不是一蹴而就。(SOA)

2. 最大可能的找到最合适的切分维度。
3. 由于数据库中间件对数据Join 实现的优劣难以把握，而且实现高性能难度极大，业务读取 尽量少使用多表Join -尽量通过数据冗余，分组避免数据垮库多表join。
4. 尽量避免分布式事务。
5. 单表拆分到数据1000万以内



## CAP三进二和Base定理

##### CAP三进二

在分布式系统中，讲究C:Consistency（强一致性）、A:Availability（可用性）、P:Partition tolerance（分区容错性）

CAP的证明基于异步网络，异步网络也是反映了真实网络中情况的模型。真实的网络系统中，节点之间不可能保持同步，即便是时钟也不可能保持同步，所有的节点依靠获得的消息来进行本地计算和通讯。这个概念其实是相当强的，意味着任何超时判断也是不可能的，因为没有共同的时间标准。之后我们会扩展CAP的证明到弱一点的异步网
络中，这个网络中时钟不完全一致，但是时钟运行的步调是一致的，这种系统是允许节点做超时判断的

CAP理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求， 最多只能同时较好的满足两个。 因此，根据 CAP 原理将 NoSQL 数据库分成了满足 CA 原则、满足 CP 原则和满足 AP 原则三大类：

- CA - 单点集群，满足一致性，可用性的系统，通常在可扩展性上不太强大。
- CP - 满足一致性，分区容忍必的系统，通常性能不是特别高
- AP - 满足可用性，分区容忍性的系统，通常可能对一致性要求低一些

##### BASE定理

BASE就是为了解决关系数据库强一致性引起的问题而引起的可用性降低而提出的解决方案

BASE其实是下面三个术语的缩写

- 基本可用（Basically Available）
- 软状态（Soft state）
- 最终一致（Eventually consistent）

它的思想是通过让系统放松对某一时刻数据一致性的要求来换取系统整体伸缩性和性能上改观。为什么这么说呢，缘由就在于大型系统往往由于地域分布和极高性能的要求，不可能采用分布式事务来完成这些指标，要想获得这些指标，我们必须采用另外一种方式来完成，这里BASE就是解决这个问题的办法

分布式一致性理论paxos、raft、zab算法



## 什么是分布式事务

分布式事务用于在分布式系统中保证不同节点之间的数据一致性。分布式事务的实现有很多种，最具有代表性的是由Oracle Tuxedo系统提出的XA分布式事务协议。
XA协议包含两阶段提交（2PC）和三阶段提交（3PC）两种实现，这里我们重点介绍两阶段提交的具体过程

#### XA两阶段提交（2PC）

在XA协议中包含着两个角色：事务协调者和事务参与者。让我们来看一看他们之
间的交互流程：

![image-20210810205852347](https://gitee.com/Sean0516/image/raw/master/img/image-20210810205852347.png)

1. 在XA分布式事务的第一阶段，作为事务协调者的节点会首先向所有的参与者节点发送Prepare请求。在接到Prepare请求之后，每一个参与者节点会各自执行与事务有关的数据更新，写入Undo Log和Redo Log。如果参与者执行成功，暂时不提交事务，而是向事务协调节点返回“完成”消息。当事务协调者接到了所有参与者的返回消息，整个分布式事务将会进入第二阶段。

   ![image-20210810205909264](https://gitee.com/Sean0516/image/raw/master/img/image-20210810205909264.png)

2. 在XA分布式事务的第二阶段，如果事务协调节点在之前所收到都是正向返回，那么它将会向所有事务参与者发出Commit请求。接到Commit请求之后，事务参与者节点会各自进行本地的事务提交，并释放锁资源。当本地事务完成提交后，将会向事务协调者返回“完成”消息。当事务协调者接收到所有事务参与者的“完成”反馈，整个分布式事务完成。

#### 2PC 提交协议有什么缺点

1. 同步阻塞问题   ，在执行过程中，所有参与节点都是事务阻塞型，当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态  （1pc 准备阶段， 只执行sql 不提交，占用数据库连接资源）

2. 单点故障   由于协调者的重要性，一旦协调者发生故障，参与者会一直阻塞下去， 尤其在第二阶段。协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作

3. 数据不一致    在二阶段提交阶段，当协调者向参与者发生commit 请求后，发生了局部网络异常或者在发送commit 请求过程中，协调者发生了故障，导致只有一部分参与者接收到 commit 请求。其他未接收到commit 请求的机器无法执行事务提交，于是整个分布式系统便出现了数据不一致的想象

4. 二阶段无法解决的问题： 协调者在发出commit 消息之后宕机， 而唯一接收到这条消息的参与者同时也宕机了， 那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也不确定。 

   
   

#### XA三阶段提交（3PC）

XA三阶段提交在两阶段提交的基础上增加了CanCommit阶段，并且引入了超时机制。一旦事物参与者迟迟没有接到协调者的commit请求，会自动进行本地commit。这样有效解决了协调者单点故障的问题。但是性能问题和不一致的问题仍然没有根本解决

#### can  commit

协调者向参与者发送commit 请求，参与者如果可以提交就返回Yes 响应，否则返回No

1. 事务询问，协调者向参与者发送can commit 请求，询问是否可以执行事务提交操作，然后开始等待参与者的响应
2. 响应反馈   参与者接收到can  commit 请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes ，并进入预备状态，否则反馈No

#### pre commit 

协调者根据参与者的反应情况来觉得是否可以进行事务的pre commit 操作，根据响应情况，有以下两种可能

##### 假如协调者从所有的参与者获得的反馈都是Yes 响应，那么就会执行事务的预执行

1. 发送预提交请求 协调者向参与者发送 pre commit  请求，并进行prepared 阶段
2. 事务预提交   参与者接收到pre commit 请求后，会执行事务参着，并将 undo 和 redo  信息记录到事务日志中
3. 响应反馈  如果参与者成功执行了事务操作 ，则返回ACK 响应，同时开始等待最终指令

假如有任何一个参与者向协调者发送了No 响应，或者等待超时之后，协调者都没有接收到参与者的响应，那么久执行事务中断

1. 发送中断请求  协调者向所有参与者都发送 abort 请求
2. 中断事务   参与者收到来自协调者的 abort请求后 ，执行事务中断

#### do commit 

该阶段进行真正的事务提交，也可以分为以下两种情况

##### 执行提交

1. 发送提交请求。  协调接收到参与者发送的ACK 响应， 那么他将从预提交状态进入到提交状态， 并向所有参与者发送 do commit 请求
2. 事务提交         参与者接收到do  commit 请求之后，执行正式的事务提交，并在完成事务提交后， 释放所有的事务资源
3. 响应反馈    事务提交完之后， 向协调者发送ACK 响应
4. 完成事务  协调者接收到所有事务参与者的ack 响应后， 完成事务

##### 中断事务

1. 发送中断请求  协调者向所有参与者发送abort请求
2. 事务回滚   参与者接收到abort请求之后，利用其在阶段二 记录的 undo 日志来执行事务的回滚操作，并在完成事务回滚之后，释放所有的事务资源
3. 反馈结果  参与者完成事务回滚之后，向协调者发送 ACK 消息
4. 中断事务 协调者接收到参与者反馈的ACK 消息之后， 执行事务的中断。 

#### 2PC 和 3PC 的区别是什么

1. 3pc 比2pc 多了一个can commit 阶段，减少了不必要资源的浪费，因为2pc 在第一阶段会占用资源， 而3pc 在这个阶段不占用资源，只是校验下SQL ，如果不能执行， 就直接返回， 减少资源占用

2. 引入超时机制，同时在协调者和参与者中都引入超时机制

   2pc ： 只有协调者有超时机制，超时后，发送回滚指令

   3pc ： 协调者和参与者都有超时机制

   协调者超时  can commit  pre commit 中 ，如果接收不到参与者的反馈 ，协调者向参与者发送中断指令

   参与者超时： pre commit 阶段 参与者进行中断。 do commit 阶段 参与者进行事务提交

   

#### MQ事务

利用消息中间件来异步完成事务的后一半更新，实现系统的最终一致性。这个方式避免了像XA协议那样的性能问题

#### TCC解决方案

TCC事务是Try、Confirm、Cancel三种指令的缩写，其逻辑模式类似于XA两阶段提交，但是实现方式是在代码层面来人为实现

TCC 是一种常用的分布式事务解决方案， 他将一个事务拆分为三个步骤

1. T （try） 业务检测阶段 ，这个阶段主要进行业务校验和检查或者资源预留，也可能是直接进行业务操作
2. C (Confirm) 业务确认阶段  ，这个阶段对try 阶段校验过的业务或预留的资源进行确认
3. C (cancel ) 业务回滚阶段   这个阶段和上面的C confirm 是互斥的， 用于释放Try 阶段预留的资源或者业务

#### TCC 空回滚是解决什么问题

在执行TCC 资源Try 方法的情况下，调用了二阶段的cancel 方法， 比如当try 请求由于网络延迟或故障等原因，没有执行。 结果返回了异常，那么此时cancel 就不能正常执行， 因为try  没有对数据进行修改。 如果cancel 进行了对数据的修改，那就会导致数据不一致

解决思路是关键要识别出这个空回滚。 思路很简单，需要知道 Try  阶段是否进行， 如果执行了，那就正常回滚， 如果没有执行， 那就是空回滚。 建议在发起全局事务时，生产全局事务记录， 全局事务ID 贯穿整个分布式事务调用链条，再额外增加一张**分支事务记录表**。 其中有全局事务ID 和分支事务ID ，第一阶段Try 方法里会插入一条记录。 表示Try 阶段执行了， cancel 接口里读取该记录。 如果该记录存在，则正常回滚， 如果记录不存在， 则是空回滚 （此时应该不进行回滚）





![image-20210810210058784](https://gitee.com/Sean0516/image/raw/master/img/image-20210810210058784.png)

#### 如何解决TCC 幂等问题

为了保证TCC 二阶段提交重试机制不会引发数据不一致，要求TCC 的二阶段 Confirm 和Cancel 接口保证幂等性，这样就不会重复使用或者是否资源，如果幂等控制没做好，很有可能导致数据不一致等严重问题

解决思路再上述 分支事务记录表中增加执行状态。 每次执行都查询该状态

#### 如何解决TCC 悬挂问题

悬挂就是对于一个分布式事务 ，其二阶段Cancel 接口比Try 接口先执行

出现原因是在调用分支事务Try 是，由于网络发生拥堵，造成了超时，TM 就会通知RM 回滚该分布式事务，可能完成回滚后，Try 请求才到达参与者真正执行，而一个try 方法预留的业务支援，只有该分布式事务才能实用，该分布式事务第一阶段预留的业务资源就再也没有人能处理了。 对于这种情况，就称为悬挂， 即业务资源预留后无法继续处理

解决思路是，如果二阶段执行完成，那么一阶段就不能再继续执行 ，在执行一阶段事务时，判断在该全局事务下，判断分支事务记录表中，是否已经有二阶段事务记录，如果有，则不再执行try



### 可靠消息服务方案是什么

可靠消息最终一致性方案是指： 当事务的发起方（事务参与者，消息发送者）执行完本地事务后，同时发出一条消息，事务参与方（事务参与者，消息的消费者） 一定能够接收消息并可以成功处理自己的事务

1. 可靠消息  ，发起方一定得把消息传递给消费者
2. 最终一致性： 最终发起方的业务处理和消费方的业务处理的完成，达到最终一致

![image-20211117145607721](https://gitee.com/Sean0516/image/raw/master/img/image-20211117145607721.png)



### 最大努力通知方案的关键是什么

1. 有一定的消息重复通知机制， 因为接收通知方可能没有接收到通知，此时要有一定的机制对消息重复通知
2. 消息校对机制。 如果尽最大努力也没有通知到接收方，或者接收方消费消息后要再次消费，此时可由接收方主动向通知方查询消息来满足需求

## 分布式系统中的幂等性

### 什么是分布式系统中的幂等

在编程中，一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。  

幂等就是一个操作，不论执行多少次，产生的效果和返回的结果都是一样的

### 幂等有那些技术解决方案

1. 查询操作 

2. 删除操作 

3. 唯一索引

4. token 机制

   防止页面重复提交

   业务要求： 页面的数据只能被点击一次提交

   发生原因  由于重复点击或者网络重复 ，或者nginx 重复等情况会导致数据被重复提交

   解决方案： 集群环境采用token 加 redis    

   处理流出： 

   1. 数据提交前要向服务的申请token ，token 放到redis 或jvm 内存，token 有效时间
   2. 提交后，后台校验token ，同时删除token ，生成新的token 返回

   token 特点  ： 要申请， 一次有效 ，可以限流

   需要注意 ： redis 要用删除操作来判断token ，删除成功代表token 校验通过

   ### 对外提高的API 如何保证幂等

   对外提高接口为了支持幂等调用， 接口有两个字段必须传 ， 一个是来源 source ， 一个来源方序列号seq ,这两个字段在提高方系统里面做联合唯一索引，这样当第三方调用时，先在本方系统里面查询，是否已经处理过了， 返回相应处理结果，如果没有处理过，进行相应处理， 返回结果

   ### 缓存和数据库双写一致性问题如何解决

   

   ### 分布式架构下，Session 共享有什么方案

   1. 不要有session ，推荐使用jwt 的token
   2. 存放到cookie 中 ，将session 存储到cookie 中 。 但是缺点明显 
   3. session同步。 服务器之间同步session ，保证每个服务器都有全部的session
   4. 将session 放在redis  中， 虽然架构上变得复杂，并且需要多访问一次redis 
   5. 使用nginx  中的ip_hash  ，同一个ip 只能在指定的同一个机器访问。 

## 分布式缓存

### 哨兵模式

![image-20210926152531243](https://gitee.com/Sean0516/image/raw/master/img/image-20210926152531243.png)

图中有2个Redis从服务器，它们会通过复制Redis主服务器的数据来完成同步。此外还有一个哨兵进程，它会通过发送命令来监测各个Redis主从服务器是否可用。当主服务器出现故障不可用时，哨兵监测到这个故障后，就会启动故障切换机制，作废当前故障的主Redis服务器，将其中的一台Redis从服务器修改为主服务器，然后将这个消息发给各个从服务器，使得它们也能做出对应的修改，这样就可以保证系统继续正常工作了。通过这段论述大家可以看出，哨兵进程实际就是代替人工，保证Redis的高可用，使得系统更加健壮

然而有时候单个哨兵也可能不太可靠，因为哨兵本身也可能出现故障，所以Redis还提供了多哨兵模式。多哨兵模式可以有效地防止单哨兵不可用的情况

![image-20210926152617190](https://gitee.com/Sean0516/image/raw/master/img/image-20210926152617190.png)

多个哨兵会相互监控，使得哨兵模式更为健壮，在这个机制中，即使某个哨兵出现故障不可用，其他哨兵也会监测整个Redis主从服务器，使得服务依旧可用



### Redis 集群

![image-20210926153044160](https://gitee.com/Sean0516/image/raw/master/img/image-20210926153044160.png)

有整数1～6的图形为一个哈希槽，哈希槽中的数字决定了数据将发送到哪台主Redis服务器进行存储。每台主服务器会配置1台到多台从Redis服务器，从服务器会同步主服务器的数据

我们知道Redis是一个key-value缓存，假如计算key的哈希值，得到一个整数，记为hashcode。如果此时执行 n =hashcode % 6 + 1 得到n  就算一个1 到6 之间的整数，然后通过哈希槽就能找到对应的服务器。 

## 秒杀架构设计

#### 业务特点

1. 瞬时并发量大
2. 库存少
3. 业务简单

#### 架构设计思想

![image-20210810205046847](https://gitee.com/Sean0516/image/raw/master/img/image-20210810205046847.png)

##### 限流

由于活动库存量一般都是很少，对应的只有少部分用户才能秒杀成功。所以我们需要限制大部分用户流量，只准少量用户流量进入后端服务器

##### 削峰

秒杀开始的那一瞬间，会有大量用户冲击进来，所以在开始时候会有一个瞬间流量峰值。如何把瞬间的流量峰值变得更平缓，是能否成功设计好秒杀系统的关键因素。实现流量削峰填谷，一般的采用缓存和 MQ 中间件来解决

##### 异步

秒杀其实可以当做高并发系统来处理，在这个时候，可以考虑从业务上做兼容，将同步的业务，设计成异步处理的任务，提高网站的整体可用性

##### 缓存

秒杀系统的瓶颈主要体现在下订单、扣减库存流程中。在这些流程中主要用到 OLTP 的数据库，类似 MySQL、SQLServer、Oracle。由于数据库底层采用 B+ 树的储存结构，对应我们随机写入与读取的效率，相对较低。如果我们把部分业务逻辑迁移到内存的缓存或者 Redis 中，会极大的提高并发效率

#### 秒杀流程图

![image-20210810205247730](https://gitee.com/Sean0516/image/raw/master/img/image-20210810205247730.png)

秒杀系统核心在于层层过滤，逐渐递减瞬时访问压力，减少最终对数据库的冲击。通过上面流程图就会发现压力最大的地方在哪里

MQ 排队服务，只要 MQ 排队服务顶住，后面下订单与扣减库存的压力都是自己能控制的，根据数据库的压力，可以定制化创建订单消费者的数量，避免出现消费者数据量过多，导致数据库压力过大或者直接宕机。

库存服务专门为秒杀的商品提供库存管理，实现提前锁定库存，避免超卖的现象。同时，通过超时处理任务发现已抢到商品，但未付款的订单，并在规定付款时间后，处理这些订单，将恢复订单商品对应的库存量

#### 总结

- 尽量将请求拦截在上游，降低下游的压力
- 充分利用缓存与消息队列，提高请求处理速度以及削峰填谷的作用





## 分布式ID

1. UUID  

   常见的方式。可以利用数据库也可以利用程序生成，一般来说全球唯一

   ###### 优点

   1. 简单，代码方便
   2. 生成ID性能非常好，基本不会有性能问题
   3. 全球唯一，在遇见数据迁移，系统数据合并，或者数据库变更等情况下，可以从容应对

   ###### 缺点

   1. 没有排序，无法保证趋势递增
   2. UUID往往是使用字符串存储，查询的效率比较低
   3. 存储空间比较大，如果是海量数据库，就需要考虑存储量的问题
   4. 传输数据量大
   5. 不可读

2. 数据库自增ID 或字段

   最常见的方式。利用数据库，全数据库唯一

   ###### 优点

   1. 简单，代码方便，性能可以接受。
   2. 数字ID天然排序，对分页或者需要排序的结果很有帮助。

   ###### 缺点

   1. 不同数据库语法和实现不同，数据库迁移的时候或多数据库版本支持的时候需要处理
   2. 在单个数据库或读写分离或一主多从的情况下，只有一个主库可以生成。有单点故障的风险。
   3. 在性能达不到要求的情况下，比较难于扩展
   4. 如果遇见多个系统需要合并或者涉及到数据迁移会相当痛苦。
   5. 分表分库的时候会有麻烦

   ###### 优化方案

   针对主库单点，如果有多个Master库，则每个Master库设置的起始数字不一样，步长一样，可以是Master的个数。比如：Master1 生成的是 1，4，7，10，Master2生成的是2,5,8,11 Master3生成的是 3,6,9,12。这样就可以有效生成集群中的唯一ID，也可以大大降低ID生成数据库操作的负载

3. Redis生成ID

   当使用数据库来生成ID性能不够要求的时候，我们可以尝试使用Redis来生成ID。这主要依赖于Redis是单线程的，所以也可以用生成全局唯一的ID。可以用Redis的原子操作 INCR和INCRBY来实现

   可以使用Redis集群来获取更高的吞吐量。假如一个集群中有5台Redis。可以初始化每台Redis的值分别是1,2,3,4,5，然后步长都是5。各个Redis生成的ID为

   另外，比较适合使用Redis来生成每天从0开始的流水号。比如订单号=日期+当日自增长号。可以每天在Redis中生成一个Key，使用INCR进行累加

   ###### 优点

   1. 不依赖于数据库，灵活方便，且性能优于数据库
   2. 数字ID天然排序，对分页或者需要排序的结果很有帮助

   ###### 缺点

   1. 如果系统中没有Redis，还需要引入新的组件，增加系统复杂度
   2. 需要编码和配置的工作量比较大。

4. Twitter的snowflake算法

   snowflake 是 twitter 开源的分布式ID生成算法，其核心思想为，一个long型的ID

   1. 符号位  占用 1位
   2. 时间戳 41 bit  - 41位的长度可以使用69年
   3. 机器编号 10 bit  （5个bit是数据中心，5个bit的机器ID） - 10位的长度最多支持部署1024个节点
   4. 序列号 12 bit  - 12位的计数顺序号支持每个节点每毫秒产生4096个ID序号

   ![image-20210812171442228](https://gitee.com/Sean0516/image/raw/master/img/image-20210812171442228.png)

   算法单机每秒内理论上最多可以生成1000*(2^12)，也就是400W的ID，完全能满足业务的需求

    snowflake算法可以根据自身项目的需要进行一定的修改。比如估算未来的数据中心个数，每个数据中心的机器数以及统一毫秒可以能的并发数来调整在算法中所需要的bit数

   ###### 优点

   1. 不依赖于数据库，灵活方便，且性能优于数据库
   2. ID按照时间在单机上是递增的

   ###### 缺点

   1. 在单机上是递增的，但是由于涉及到分布式环境，每台机器上的时钟不可能完全同步，也许有时候也会出现不是全局递增的情况 
   1. 时间回拨 ，如果机器时间改变，可能生成一样的ID 



## 分布式锁有哪些解决方案

1. redis 分布式锁 。 通过 setnx  设置key ,value  （key 需要设置过期时间， 主要是为了解决程序失效 的问题。） 删除 key 的时候，需要删除属于自己的锁的key (判断当前key 的值和当前线程一致)  使用 watch dog  来实现锁的过期时间更新

   1. redis 做分布式锁用什么命令  使用 SETNX   (SET IF NOT Exists  如果不存在，则Set  ,如果给定的key 存在，则不做任何操作)

      格式  setnx key value   

   2. Redis 分布式锁死锁那些情况，如何解决

      1. 加锁， 没有释放锁 ，需要加释放锁的操作 ，比如  delete key
      2. 加锁后， 程序还没有执行释放锁 ，程序挂了 ，需要使用Key 的过期机制

2. 基于 zookeeper  ，基于临时节点。 顺序节点

   ![image-20211109213948639](https://gitee.com/Sean0516/image/raw/master/img/image-20211109213948639.png)

3. 基于数据库  主键或者唯一索引的唯一性 

   在mysql 数据库中创建一张表，设置一个主键或者 唯一键 ，这个key 就是要锁的 key 。因此同一个Key 在mysql 表里只能插入一次。 这样对锁的竞争交给数据库。 

### zookeeper  和redis  做分布式锁的区别

Redis  ：

1. redis  只保证最终一致性， 副本间的数据复制是异步进行 （Redis 集群一般是读写分离架构，存在主从同步延迟情况） 主从切换之后，可能有部分数据没有复制过去，可能会出现 锁丢失的情况 ，因此，在强一致性要求的业务不推荐使用redis ，推荐使用zk
2. redis  集群各个方法的响应时间最低

zookeeper  

1. 使用zookeeper 集群， 可能会导致session 超时时导致锁被错误释放，因此zookeeper 也无法保证完全一致性
2. zookeeper 有较好的稳定性，响应时间抖动小，没有出现异常，但是随着并发量和业务数量提升，其响应时间和QPS 会明显下降

总结

1. zookeeper 每次进行锁操作前都要创建若干节点，完成后要释放节点，会浪费很多时间
2. redis  只是简单的数据操作，没有这个问题

## 常见的限流算法

### 计数器法

计数器法是限流算法里最简单也是最容易实现的一种算法。比如我们规定，对于A接口来说，我们1分钟的访问次数不能超过100个。那么我们可以这么做：在一开 始的时候，我们可以设置一个计数器counter，每当一个请求过来的时候，counter就加1，如果counter的值大于100并且该请求与第一个 请求的间隔时间还在1分钟之内，那么说
明请求数过多；如果该请求与第一个请求的间隔时间大于1分钟，且counter的值还在限流范围内，那么就重置counter

这个算法虽然简单，但是有一个十分致命的问题，那就是临界问题

#### 滑动窗口

滑动窗口，又称rolling window。为了解决这个问题，我们引入了滑动窗口算法。如果学过TCP网络协议的话，那么一定对滑动窗口这个名词不会陌生。下面这张图，很好地解释了滑动窗口算法

![image-20210810210930993](https://gitee.com/Sean0516/image/raw/master/img/image-20210810210930993.png)

在上图中，整个红色的矩形框表示一个时间窗口，在我们的例子中，一个时间窗口就是一分钟。然后我们将时间窗口进行划分，比如图中，我们就将滑动窗口 划成了6格，所以每格代表的是10秒钟。每过10秒钟，我们的时间窗口就会往右滑动一格。每一个格子都有自己独立的计数器counter，比如当一个请求 在0:35秒的时候到达，那么
0:30~0:39对应的counter就会加1

计数器算法其实就是滑动窗口算法。只是它没有对时间窗口做进一步地划分，所以只有1格。由此可见，当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。

#### 漏桶算法

![image-20210810211026116](https://gitee.com/Sean0516/image/raw/master/img/image-20210810211026116.png)

漏桶算法的原理和他的名字一样，我们维持一个漏斗，它有恒定的流出速度，不管水流流入的速度有多快，漏斗出水的速度始终保持不变。

漏桶的容量= 漏桶的流出速度* 可接收的等待时长，在这个容量范围内的请求可以排队等待系统的处理，超过这个容量的请求，才会被抛弃

在漏桶限流算法中，存在下面几种情况

1. 当请求速度大于漏桶的流出速度时， 也就是请求量大于当前服务所能处理的最大极限值时，触发限流策略
2. 请求速度小于或等于漏桶的流出速度时，也就是服务的处理能力大于或等于请求量时，正常执行

漏桶算法有一个缺点： 当系统在短时间内有突发的大流量时，漏桶算法处理不了



#### 令牌桶算法

![image-20210810211114037](https://gitee.com/Sean0516/image/raw/master/img/image-20210810211114037.png)

从图中我们可以看到，令牌桶算法比漏桶算法稍显复杂。首先，我们有一个固定容量的桶，桶里存放着令牌（token）。桶一开始是空的，token以 一个固定的速率r往桶里填充，直到达到桶的容量，多余的令牌将会被丢弃。每当一个请求过来时，就会尝试从桶里移除一个令牌，如果没有令牌的话，请求无法通 过

令牌桶算法，由于有一个桶的存在，可以处理短时间大流量的场景，这是令牌桶和漏桶的区别



#### 计数器 VS 滑动窗口

计数器算法是最简单的算法，可以看成是滑动窗口的低精度实现。滑动窗口由于需要存储多份的计数器（每一个格子存一份），所以滑动窗口在实现上需要更多的存储空间。也就是说，如果滑动窗口的精度越高，需要的存储空间就越大。

#### 漏桶算法 VS 令牌桶算法

漏桶算法和令牌桶算法最明显的区别是令牌桶算法允许流量一定程度的突发。因为默认的令牌桶算法，取走token是不需要耗费时间的，也就是说，假设桶内有100个token时，那么可以瞬间允许100个请求通过

令牌桶算法由于实现简单，且允许某些流量的突发，对用户友好，所以被业界采用地较多。当然我们需要具体情况具体分析，只有最合适的算法，没有最优的算法



### BitMap

#### Bit-map的基本思想

32位机器上，对于一个整型数，比如int a=1 在内存中占32bit位，这是为了方便计算机的运算。但是对于某些应用场景而言，这属于一种巨大的浪费，因为我们可以用对应的32bit位对应存储十进制的0-31个数，而这就是Bit-map的基本思想。Bit-map算法利用这种思想处理大量数据的排序、查询以及去重。 Bitmap在用户群做交集和并集运算的时候也有极大的便利

#### Bit-map扩展——Bloom Filter(布隆过滤器)

当一个元素被加入集合中时,通过k各散列函数将这个元素映射成一个位数组中的k个点,并将这k个点全部置为1.有一定的误判率--在判断一个元素是否属于某个集合时,有可能会把不属于这个集合的元素误判为属于这个集合.因此,它不适合那些"零误判"的应用场合.在能容忍低误判的应用场景下,布隆过滤器通过极少的误判换区了存储空间的极大节省



Bloom Filter使用k个相互独立的哈希函数（Hash Function），它们分别将集合中的每个元素映射到{1,…,m}的范围中。对任意一个元素x，第i个哈希函数映射的位置hi(x)就会被置为1（1≤i≤k）。注：如果一个位置多次被置为1，那么只有第一次会起作用，后面几次将没有任何效果   在判断y是否属于这个集合时，对y应用k次哈希函数，若所有hi(y)的位置都是1（1≤i≤k），就认为y是集合中的元素，否则就认为y不是集合中的元素

#### 总结

使用Bit-map的思想，我们可以将存储空间进行压缩，而且可以对数字进行快速排序、去重和查询的操作。Bloom Fliter是Bit-map思想的一种扩展，它可以在允许低错误率的场景下，大大地进行空间压缩，是一种拿错误率换取空间的数据结构





### Top k 问题 （海量数据中找出出现频率最好的前k个数）

针对top K类问题，通常比较好的方案是分治+Trie树/hash+小顶堆（就是上面提到的最小堆），即先将数据集按照Hash方法分解成多个小数据集，然后使用Trie树活着Hash统计每个小数据集中的query词频，之后用小顶堆求出每个数据集中出现频率最高的前K个数，最后在所有top K中求出最终的top K

###### 有1亿个浮点数，如果找出期中最大的10000个

1. 数据全部排序

   最容易想到的方法是将数据全部排序，然后在排序后的集合中进行查找，最快的排序算法的时间复杂度一般为O（nlogn），如快速排序。但是在32位的机器上，每个float类型占4个字节，1亿个浮点数就要占用400MB的存储空间，对于一些可用内存小于400M的计算机而言，很显然是不能一次将全部数据读入内存进行排序的。其实即使内存能够满足要求（我机器内存都是8GB），该方法也并不高效，因为题目的目的是寻找出最大的10000个数即可，而排序却是将所有的元素都排序了，做了很多的无用功

2. 局部淘汰法

   第二种方法为局部淘汰法，该方法与排序方法类似，用一个容器保存前10000个数，然后将剩余的所有数字——与容器内的最小数字相比，如果所有后续的元素都比容器内的10000个数还小，那么容器内这个10000个数就是最大10000个数。如果某一后续元素比容器内最小数字大，则删掉容器内最小元素，并将该元素插入容器，最后遍历完这1亿个数，得到的结果容器中保存的数即为最终结果了。此时的时间复杂度为O（n+m^2），其中m为容器的大
   小，即10000

3. 分治法

   第三种方法是分治法，将1亿个数据分成100份，每份100万个数据，找到每份数据中最大的10000个，最后在剩下的10010000个数据里面找出最大的10000个。如果100万数据选择足够理想，那么可以过滤掉1亿数据里面99%的数据。100万个数据里面查找最大的10000个数据的方法如下：用快速排序的方法，将数据分为2堆，如果大的那堆个数N大于10000个，继续对大堆快速排序一次分成2堆，如果大的那堆个数N大于10000个，继续对大堆快速排序一次分成2堆，如果大堆个数N小于10000个，就在小的那堆里面快速排序一次，找第10000-n大的数字；递归以上过程，就可以找到第1w大的数。参考上面的找出第1w大数字，就可以类似的方法找到前10000大数字了。此种方法需要每次的内存空间为10^64=4MB，一共需要101次这样的比较

4. Hash法

   第四种方法是Hash法。如果这1亿个书里面有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很高的话，会减少很大的内存用量，从而缩小运算空间，然后通过分治法或最小堆法查找最大的10000个数

5. 最小堆

   首先读入前10000个数来创建大小为10000的最小堆，建堆的时间复杂度为O（mlogm）（m为数组的大小即为10000），然后遍历后续的数字，并于堆顶（最小）数字进行比较。如果比最小的数小，则继续读取后续数字；如果比堆顶数字大，则替换堆顶元素并重新调整堆为最小堆。整个过程直至1亿个数全部遍历完为止。然后按照中序遍历的方式输出当前堆中的所有10000个数字。该算法的时间复杂度为O（nmlogm），空间复杂度是10000（常数）

### Jenkins 

![image-20210812164657035](https://gitee.com/Sean0516/image/raw/master/img/image-20210812164657035.png)



### 带有过期时间的LRU缓存

LRU，全称Least Recently Used，最近最少使用缓存

###### LRU算法的设计原则

如果一个数据在最近一段时间没有被访问到，那么在将来它被访问的可能性也很小 也就是说，当限定的空间已存满数据时，应当把最久没有被访问到的数据淘汰

###### 实现：

利用链表和HashMap。当需要插入新数据项，在链表中命中，则把该节点移到链表头部 不存在，则新建一个节点，放在链表头部，若缓存满，则把链表最后一个节点删除即可。 在访问数据时，若数据项在链表中存在，则把该节点移到链表头部，否则返回-1 这样一来在链表尾部的节点就是最近最久未访问的数据项

###### set(key,value)

若key在hashmap中存在，则先重置value，然后获取对应节点cur，将其从链表删除，并移到链表头 不存在，则新建一个节点，并将节点放到链表的头部。 当Cache满，删除链表最后一个节点

###### get(key)

若key在hashmap中存在，把对应的节点放到链表头，并返回对应value 若不存在，则返回-1 即保证基本的get/set同时，还要保证最近访问(get或put)的节点保持在限定容量的Cache中，如果超过容量则应该把LRU(近期最少使用)的节点删除掉

